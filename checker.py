import subprocess, re , os
from string_checker import txtFileChecker
from csv import reader, writer
from db_handler import *

# dictionary keys
PACKAGE = "package"
VERSION = "version"
FULL_PATH = "full_path"
DIRECTORY = "directory"
FILE_NAME = "file_name"
FILE_OUTPUT = "file_info_output"
MD5="md5"
SHA1 ="sha1"
SHA256 = "sha256"
B2 = "b2"
STRINGS = "strings"
READELF = "readelf"
VULNERABLE_FUNC= "vulnerable_functions"
SECRET_KEYS = "secret_keys"
CHECKSEC = "checksec"
c_suffix = "@GLIBC" #c_suffix differentiates between library func and user-defined func

func_list = None


def main():
    global func_list
    create_tables()
    func_list = load_functions_from_csv()
    libs = get_installed_libraries()
    for lib in libs:
        scan_library(lib)


def get_directory(path):
    dir_path = os.path.dirname(path) 
    dir_name = os.path.basename(dir_path) 
    return dir_name

def get_file_name(path):
    return os.path.basename(path) 

# gets the objdump of each file and adds keywords to dictionary
def scan_binary(path):
    dump = subprocess.run(['objdump', '-D', path], stdout=subprocess.PIPE).stdout.decode('utf-8')
    found = set()
    for func_word in func_list:
        if f"{func_word}{c_suffix}" in dump: 
            #c_suffix is 'GCLIB', this differentiates between library func and user-defined func
            found.add(func_word)    
    row_dict = {}
    row_dict[READELF] = subprocess.run(f"readelf -a {path}", shell=True,stdout=subprocess.PIPE).stdout.decode('utf-8')
    row_dict[VULNERABLE_FUNC] = str(found)
    command = f"~/checksec/checksec.sh/./checksec --verbose --extended --file={path}"
    output = subprocess.run(command, shell=True,stdout=subprocess.PIPE).stdout.decode('utf-8')
    row_dict[CHECKSEC] = output
    return row_dict

def load_functions_from_csv():
    # read csv file as a list of lists
    with open('vulnerable_functions.csv', 'r') as read_obj:
        # pass the file object to reader() to get the reader object
        csv_reader = reader(read_obj)
        # Pass reader object to list() to get a list of lists
        list_of_rows = list(csv_reader)
        return list(map(lambda x: x[0],list_of_rows))

""" params one row entry outputted by dpkg -l
    returns dictionary of library info
"""
def row_to_dictionary(row):
    field_pattern = r'\s+\S+\s+\S+\s+\S+'
    str_without_i = re.findall(field_pattern,row)[0]
    field_list= re.split(r'\s+',str_without_i)
    lib_dict = {"name":field_list[1] , "version": field_list[2], "architecture": field_list[3]}
    return lib_dict

"""
    runs linux call dpkg -l and outputs list of libraries
    each library is of form dictionary {name, version, architecture}
"""
def get_installed_libraries():
    row_pattern = r'ii\s+\S+\s+\S+\s+\S+'
    result = subprocess.run("dpkg -l",shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')
    rows = re.findall(row_pattern,result)
    library_list = list(map(row_to_dictionary,rows))
    return library_list


def scan_library(library):
    library_name = library["name"]
    version = library["version"]
    output = subprocess.run(['dpkg', '-L', library_name], stdout=subprocess.PIPE).stdout.decode('utf-8')
    path_list = output.split("\n")
    path_list_filtered = list(filter(lambda x: os.path.isfile(x) ,path_list))
    for path in path_list_filtered:
        checkPath(path, library_name, version)
    # pass lists to respective functions

    
"""
    param: file path 
    returns: TEXT, ELF, LINK based on file type
"""    
def get_file_type(file_info):
    if "text" in file_info:
        return "text"
    elif "ELF" in file_info or "executable" in file_info:
        return "binary"
    elif "symbolic link" in file_info:
        return "link"
    else:
        return None

        #1) check what filetype it is
        #2) if text or elf, append to list
        #3) if link
def checkPath(path:str, package_name:str, version: str):
    path = path.strip(' \t\n\r')
    if len(path)>0:
        command = "file "+path
        file_info = subprocess.run(command,shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')
        entry_dict = {}
        file_type = get_file_type(file_info)
        isTxt = file_type == "text"
        isELF = file_type == "binary"
        if isTxt or isELF:
            if file_type == "text":
                entry_dict = txtFileChecker(path)
                ## path + strings output + keys
            else:              
                #binary
                entry_dict = scan_binary(path)
            if entry_dict != None:
                entry_dict[PACKAGE] = package_name
                entry_dict[VERSION] = version
                entry_dict[FULL_PATH] = path
                path_file = os.path.dirname(path)
                entry_dict[DIRECTORY] = os.path.basename(path_file)
                entry_dict[FILE_NAME] = os.path.split(path)[-1]
                entry_dict[FILE_OUTPUT] = file_info
                hash_dict = generate_hashes(path)
                entry_dict[SHA1] = hash_dict[SHA1]
                entry_dict[SHA256] = hash_dict[SHA256]
                entry_dict[MD5] = hash_dict[MD5]
                entry_dict[B2] = hash_dict[B2]
                if isTxt:
                    insert_text(entry_dict)
                if isELF:
                    insert_executable(entry_dict)
        elif (file_type == "link"):
            command="readlink -f "+path
            pointed_to = subprocess.run(command, shell=True,stdout=subprocess.PIPE).stdout.decode('utf-8')
            command = "dpkg -S " + pointed_to
            package_name_pointed_to =  subprocess.run(command, shell=True,stdout=subprocess.PIPE).stdout.decode('utf-8')
            package_name_pointed_to = package_name_pointed_to.split(':')[0]
            command = f"dpkg -s {package_name_pointed_to} | grep '^Version'"
            package_version = subprocess.run(command, shell=True,stdout=subprocess.PIPE).stdout.decode('utf-8')
            package_version = package_version.split(':')[1].strip(' \n')
            #ASK YOTAM- not sure this is ok to do
            checkPath(pointed_to,package_name_pointed_to, package_version)
"""
    row_dictionary: row- list of strings that represents row in csv to add
"""
def generate_hashes(path):
    hashes = {SHA1: "", MD5: "", SHA256: "", B2: ""}
    for key in hashes.keys():
        output = subprocess.run(f"{key}sum {path}", shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')
        hashes[key] = output.split(' ')[0]
    return hashes
#entry point





if __name__ == '__main__':
    main()