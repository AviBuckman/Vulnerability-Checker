import subprocess, re
from string_checker.py import txtFileChecker
from csv import reader, writer

text_list= set()
elf_list= set()
file_info_dict = {}

# gets the objdump of each file and adds keywords to dictionary
def scan_binary(path):
    dump = subprocess.run(['objdump', '-D', path], stdout=subprocess.PIPE).stdout.decode('utf-8')
    found = set()
    for func_word in func_list:
        if func_word in dump:
            found.add(func_word)    
    return found         


def load_functions_from_csv():
    # read csv file as a list of lists
    with open('vulnerable_functions.csv', 'r') as read_obj:
        # pass the file object to reader() to get the reader object
        csv_reader = reader(read_obj)
        # Pass reader object to list() to get a list of lists
        list_of_rows = list(csv_reader)
        return list(map(lambda x: x[0],list_of_rows))

""" params one row entry outputted by dpkg -l
    returns dictionary of library info
"""
def row_to_dictionary(row):
    field_pattern = r'\s+\S+\s+\S+\s+\S+'
    str_without_i = re.findall(field_pattern,row)[0]
    field_list= re.split(r'\s+',str_without_i)
    lib_dict = {"name":field_list[1] , "version": field_list[2], "architecture": field_list[3]}
    return lib_dict

"""
    runs linux call dpkg -l and outputs list of libraries
    each library is of form dictionary {name, version, architecture}
"""
def get_installed_libraries():
    row_pattern = r'ii\s+\S+\s+\S+\s+\S+'
    result = subprocess.run("dpkg -l",shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')
    rows = re.findall(row_pattern,result)
    library_list = list(map(row_to_dictionary,rows))
    return library_list


def scan_library(library):
    output = subprocess.run(['dpkg', '-L', library["name"]], stdout=subprocess.PIPE).stdout.decode('utf-8')
    path_list = output.split("\n")
    pattern = re.compile(r"\S+\.\w+$")  #this means "all strings witout spaces that end if .[a-Z]+"
    path_list_filtered = list(filter(lambda x: pattern.match(x) != None ,path_list))
    for path in path_list_filtered: 
        checkPath(path)
    # pass lists to respective functions

    
def is_executable(file_info):
    return "ELF" in file_info or "executable" in file_info 
"""
    param: file path 
    returns: TEXT, ELF, LINK based on file type
"""    
def get_file_type(file_info):
    if "text" in file_info:
        #ascii text executable not caught here
        #generate list of file() outputs, sort, examine --> fine tune the search
        return "TEXT"
    elif "ELF" in file_info:
        return "ELF"
    elif "symbolic link" in file_info:
        return "LINK"
    else:
        return None

        #1) check what filetype it is
        #2) if text or elf, append to list
        #3) if link 
def checkPath(path):
    if len(path)>0:
        command = f"file {path}"
        file_info = subprocess.run(command,shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')
    
    file_type = get_file_type(file_info)
    if file_type == "TEXT":
        entry_dict = txtFileChecker(path)
    elif file_type == "ELF":
        entry_dict = elf_list.add(path)
    elif file_type == "LINK":
        command="readlink -f "+path
        pointed_to = subprocess.run(command, shell=True,stdout=subprocess.PIPE).stdout.decode('utf-8')
        checkPath(pointed_to)    

    #if entry_dict != None:
        #add package name to dict
        #add directory name (just the name of immediate folder)
        #file name
        #add file() output
        #call hash function
        #insert the dict to csv
    
    add_row(entry_dict)

def write_iterable_csv(iterable):
    with open('file_types.csv','w') as result_file:
        wr = writer(result_file, dialect='excel')
        wr.writerows(iterable)


"""
    row_dictionary: row- list of strings that represents row in csv to add
"""
def add_row(row_dictionary):
    row = [""]*12
    with open('DB_file.csv', 'a+' , newline='') as DB_file:
        wr = writer(DB_file, dialect='excel')
        wr.writerow(row)




#entry point
func_list = load_functions_from_csv()
libs = get_installed_libraries()
for lib in libs:
    scan_library(lib)
        


sorted_keys = sorted(file_info_dict.keys())
list_to_write = []
for key in sorted_keys:
    list_to_write.append([key,file_info_dict[key]])
write_iterable_csv(list_to_write)


    